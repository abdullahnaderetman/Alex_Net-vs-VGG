{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMH9pWHuD8DMjAU/cqKKUcg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/abdullahnaderetman/Alex_Net-vs-VGG/blob/main/vgg_vs_alex_net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wo4K-A5fbO91",
        "outputId": "177c7d13-c133-48ee-a6ea-f25edf9651b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:03<00:00, 44.2MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CIFAR-10 CNN Architecture Experiment\n",
            "===================================\n",
            "Training on device: cuda:0\n",
            "\n",
            "[AlexNet Training]\n",
            "[AlexNet - Epoch 1, Batch 100] Loss: 2.063, Acc: 21.12%\n",
            "[AlexNet - Epoch 1, Batch 200] Loss: 1.721, Acc: 27.94%\n",
            "[AlexNet - Epoch 1, Batch 300] Loss: 1.576, Acc: 32.14%\n",
            "AlexNet Epoch 1 - Train Acc: 35.31%, Test Acc: 50.10%, Time: 20.90s\n",
            "[AlexNet - Epoch 2, Batch 100] Loss: 1.382, Acc: 49.61%\n",
            "[AlexNet - Epoch 2, Batch 200] Loss: 1.340, Acc: 50.35%\n",
            "[AlexNet - Epoch 2, Batch 300] Loss: 1.272, Acc: 51.65%\n",
            "AlexNet Epoch 2 - Train Acc: 52.43%, Test Acc: 60.78%, Time: 20.01s\n",
            "[AlexNet - Epoch 3, Batch 100] Loss: 1.169, Acc: 57.80%\n",
            "[AlexNet - Epoch 3, Batch 200] Loss: 1.161, Acc: 58.26%\n",
            "[AlexNet - Epoch 3, Batch 300] Loss: 1.141, Acc: 58.43%\n",
            "AlexNet Epoch 3 - Train Acc: 59.14%, Test Acc: 64.83%, Time: 18.63s\n",
            "[AlexNet - Epoch 4, Batch 100] Loss: 1.056, Acc: 62.20%\n",
            "[AlexNet - Epoch 4, Batch 200] Loss: 1.047, Acc: 62.43%\n",
            "[AlexNet - Epoch 4, Batch 300] Loss: 1.018, Acc: 63.08%\n",
            "AlexNet Epoch 4 - Train Acc: 63.47%, Test Acc: 67.75%, Time: 19.13s\n",
            "[AlexNet - Epoch 5, Batch 100] Loss: 0.948, Acc: 66.22%\n",
            "[AlexNet - Epoch 5, Batch 200] Loss: 0.942, Acc: 66.45%\n",
            "[AlexNet - Epoch 5, Batch 300] Loss: 0.918, Acc: 66.87%\n",
            "AlexNet Epoch 5 - Train Acc: 67.05%, Test Acc: 70.28%, Time: 19.82s\n",
            "[AlexNet - Epoch 6, Batch 100] Loss: 0.872, Acc: 69.55%\n",
            "[AlexNet - Epoch 6, Batch 200] Loss: 0.847, Acc: 70.11%\n",
            "[AlexNet - Epoch 6, Batch 300] Loss: 0.861, Acc: 69.90%\n",
            "AlexNet Epoch 6 - Train Acc: 70.18%, Test Acc: 68.90%, Time: 19.79s\n",
            "[AlexNet - Epoch 7, Batch 100] Loss: 0.824, Acc: 71.12%\n",
            "[AlexNet - Epoch 7, Batch 200] Loss: 0.810, Acc: 71.63%\n",
            "[AlexNet - Epoch 7, Batch 300] Loss: 0.781, Acc: 72.16%\n",
            "AlexNet Epoch 7 - Train Acc: 72.37%, Test Acc: 74.24%, Time: 18.72s\n",
            "[AlexNet - Epoch 8, Batch 100] Loss: 0.770, Acc: 73.08%\n",
            "[AlexNet - Epoch 8, Batch 200] Loss: 0.784, Acc: 73.05%\n",
            "[AlexNet - Epoch 8, Batch 300] Loss: 0.750, Acc: 73.37%\n",
            "AlexNet Epoch 8 - Train Acc: 73.59%, Test Acc: 73.50%, Time: 18.77s\n",
            "[AlexNet - Epoch 9, Batch 100] Loss: 0.747, Acc: 74.30%\n",
            "[AlexNet - Epoch 9, Batch 200] Loss: 0.718, Acc: 74.80%\n",
            "[AlexNet - Epoch 9, Batch 300] Loss: 0.723, Acc: 74.74%\n",
            "AlexNet Epoch 9 - Train Acc: 74.79%, Test Acc: 76.24%, Time: 20.07s\n",
            "[AlexNet - Epoch 10, Batch 100] Loss: 0.698, Acc: 75.70%\n",
            "[AlexNet - Epoch 10, Batch 200] Loss: 0.713, Acc: 75.42%\n",
            "[AlexNet - Epoch 10, Batch 300] Loss: 0.711, Acc: 75.49%\n",
            "AlexNet Epoch 10 - Train Acc: 75.73%, Test Acc: 76.39%, Time: 19.74s\n",
            "\n",
            "[VGG16 Training]\n",
            "[VGG16 - Epoch 1, Batch 100] Loss: 2.303, Acc: 10.12%\n",
            "[VGG16 - Epoch 1, Batch 200] Loss: 2.303, Acc: 10.16%\n",
            "[VGG16 - Epoch 1, Batch 300] Loss: 2.303, Acc: 9.90%\n",
            "VGG16 Epoch 1 - Train Acc: 9.85%, Test Acc: 10.00%, Time: 23.26s\n",
            "[VGG16 - Epoch 2, Batch 100] Loss: 2.303, Acc: 10.25%\n",
            "[VGG16 - Epoch 2, Batch 200] Loss: 2.303, Acc: 10.12%\n",
            "[VGG16 - Epoch 2, Batch 300] Loss: 2.303, Acc: 10.04%\n",
            "VGG16 Epoch 2 - Train Acc: 10.03%, Test Acc: 10.00%, Time: 23.05s\n",
            "[VGG16 - Epoch 3, Batch 100] Loss: 2.303, Acc: 10.09%\n",
            "[VGG16 - Epoch 3, Batch 200] Loss: 2.303, Acc: 9.91%\n",
            "[VGG16 - Epoch 3, Batch 300] Loss: 2.303, Acc: 9.82%\n",
            "VGG16 Epoch 3 - Train Acc: 9.73%, Test Acc: 10.00%, Time: 23.09s\n",
            "[VGG16 - Epoch 4, Batch 100] Loss: 2.303, Acc: 10.54%\n",
            "[VGG16 - Epoch 4, Batch 200] Loss: 2.303, Acc: 10.03%\n",
            "[VGG16 - Epoch 4, Batch 300] Loss: 2.303, Acc: 9.78%\n",
            "VGG16 Epoch 4 - Train Acc: 9.74%, Test Acc: 10.00%, Time: 23.23s\n",
            "[VGG16 - Epoch 5, Batch 100] Loss: 2.303, Acc: 10.03%\n",
            "[VGG16 - Epoch 5, Batch 200] Loss: 2.303, Acc: 9.79%\n",
            "[VGG16 - Epoch 5, Batch 300] Loss: 2.303, Acc: 9.85%\n",
            "VGG16 Epoch 5 - Train Acc: 9.87%, Test Acc: 10.00%, Time: 23.17s\n",
            "[VGG16 - Epoch 6, Batch 100] Loss: 2.303, Acc: 9.79%\n",
            "[VGG16 - Epoch 6, Batch 200] Loss: 2.303, Acc: 9.82%\n",
            "[VGG16 - Epoch 6, Batch 300] Loss: 2.303, Acc: 9.84%\n",
            "VGG16 Epoch 6 - Train Acc: 9.70%, Test Acc: 10.00%, Time: 23.06s\n",
            "[VGG16 - Epoch 7, Batch 100] Loss: 2.303, Acc: 9.55%\n",
            "[VGG16 - Epoch 7, Batch 200] Loss: 2.303, Acc: 9.73%\n",
            "[VGG16 - Epoch 7, Batch 300] Loss: 2.303, Acc: 9.75%\n",
            "VGG16 Epoch 7 - Train Acc: 9.73%, Test Acc: 10.00%, Time: 22.92s\n",
            "[VGG16 - Epoch 8, Batch 100] Loss: 2.303, Acc: 9.43%\n",
            "[VGG16 - Epoch 8, Batch 200] Loss: 2.303, Acc: 9.75%\n",
            "[VGG16 - Epoch 8, Batch 300] Loss: 2.303, Acc: 9.82%\n",
            "VGG16 Epoch 8 - Train Acc: 9.77%, Test Acc: 10.00%, Time: 23.09s\n",
            "[VGG16 - Epoch 9, Batch 100] Loss: 2.303, Acc: 8.90%\n",
            "[VGG16 - Epoch 9, Batch 200] Loss: 2.303, Acc: 9.54%\n",
            "[VGG16 - Epoch 9, Batch 300] Loss: 2.303, Acc: 9.44%\n",
            "VGG16 Epoch 9 - Train Acc: 9.50%, Test Acc: 10.00%, Time: 23.09s\n",
            "[VGG16 - Epoch 10, Batch 100] Loss: 2.303, Acc: 10.08%\n",
            "[VGG16 - Epoch 10, Batch 200] Loss: 2.303, Acc: 10.00%\n",
            "[VGG16 - Epoch 10, Batch 300] Loss: 2.303, Acc: 9.97%\n",
            "VGG16 Epoch 10 - Train Acc: 9.91%, Test Acc: 10.00%, Time: 23.05s\n",
            "\n",
            "[VGG16 with BatchNorm Training]\n",
            "[VGG16_BN - Epoch 1, Batch 100] Loss: 1.968, Acc: 20.56%\n",
            "[VGG16_BN - Epoch 1, Batch 200] Loss: 1.719, Acc: 25.64%\n",
            "[VGG16_BN - Epoch 1, Batch 300] Loss: 1.588, Acc: 29.56%\n",
            "VGG16_BN Epoch 1 - Train Acc: 32.31%, Test Acc: 43.61%, Time: 25.13s\n",
            "[VGG16_BN - Epoch 2, Batch 100] Loss: 1.429, Acc: 45.98%\n",
            "[VGG16_BN - Epoch 2, Batch 200] Loss: 1.355, Acc: 47.80%\n",
            "[VGG16_BN - Epoch 2, Batch 300] Loss: 1.259, Acc: 50.17%\n",
            "VGG16_BN Epoch 2 - Train Acc: 52.20%, Test Acc: 53.72%, Time: 24.94s\n",
            "[VGG16_BN - Epoch 3, Batch 100] Loss: 1.126, Acc: 61.14%\n",
            "[VGG16_BN - Epoch 3, Batch 200] Loss: 1.046, Acc: 62.26%\n",
            "[VGG16_BN - Epoch 3, Batch 300] Loss: 1.000, Acc: 63.27%\n",
            "VGG16_BN Epoch 3 - Train Acc: 64.25%, Test Acc: 60.85%, Time: 24.90s\n",
            "[VGG16_BN - Epoch 4, Batch 100] Loss: 0.901, Acc: 68.77%\n",
            "[VGG16_BN - Epoch 4, Batch 200] Loss: 0.895, Acc: 69.12%\n",
            "[VGG16_BN - Epoch 4, Batch 300] Loss: 0.832, Acc: 69.89%\n",
            "VGG16_BN Epoch 4 - Train Acc: 70.46%, Test Acc: 69.57%, Time: 24.98s\n",
            "[VGG16_BN - Epoch 5, Batch 100] Loss: 0.785, Acc: 73.89%\n",
            "[VGG16_BN - Epoch 5, Batch 200] Loss: 0.754, Acc: 74.25%\n",
            "[VGG16_BN - Epoch 5, Batch 300] Loss: 0.743, Acc: 74.43%\n",
            "VGG16_BN Epoch 5 - Train Acc: 74.59%, Test Acc: 71.07%, Time: 25.12s\n",
            "[VGG16_BN - Epoch 6, Batch 100] Loss: 0.700, Acc: 76.54%\n",
            "[VGG16_BN - Epoch 6, Batch 200] Loss: 0.655, Acc: 77.34%\n",
            "[VGG16_BN - Epoch 6, Batch 300] Loss: 0.675, Acc: 77.53%\n",
            "VGG16_BN Epoch 6 - Train Acc: 77.65%, Test Acc: 76.93%, Time: 25.04s\n",
            "[VGG16_BN - Epoch 7, Batch 100] Loss: 0.627, Acc: 79.51%\n",
            "[VGG16_BN - Epoch 7, Batch 200] Loss: 0.627, Acc: 79.23%\n",
            "[VGG16_BN - Epoch 7, Batch 300] Loss: 0.610, Acc: 79.59%\n",
            "VGG16_BN Epoch 7 - Train Acc: 79.93%, Test Acc: 77.65%, Time: 24.98s\n",
            "[VGG16_BN - Epoch 8, Batch 100] Loss: 0.570, Acc: 81.50%\n",
            "[VGG16_BN - Epoch 8, Batch 200] Loss: 0.565, Acc: 81.55%\n",
            "[VGG16_BN - Epoch 8, Batch 300] Loss: 0.563, Acc: 81.70%\n",
            "VGG16_BN Epoch 8 - Train Acc: 81.80%, Test Acc: 81.50%, Time: 24.81s\n",
            "[VGG16_BN - Epoch 9, Batch 100] Loss: 0.518, Acc: 83.23%\n",
            "[VGG16_BN - Epoch 9, Batch 200] Loss: 0.531, Acc: 83.09%\n",
            "[VGG16_BN - Epoch 9, Batch 300] Loss: 0.520, Acc: 83.19%\n",
            "VGG16_BN Epoch 9 - Train Acc: 83.22%, Test Acc: 82.02%, Time: 24.81s\n",
            "[VGG16_BN - Epoch 10, Batch 100] Loss: 0.483, Acc: 84.48%\n",
            "[VGG16_BN - Epoch 10, Batch 200] Loss: 0.486, Acc: 84.45%\n",
            "[VGG16_BN - Epoch 10, Batch 300] Loss: 0.474, Acc: 84.58%\n",
            "VGG16_BN Epoch 10 - Train Acc: 84.52%, Test Acc: 80.38%, Time: 25.00s\n",
            "\n",
            "[VGG8 Training]\n",
            "[VGG8 - Epoch 1, Batch 100] Loss: 1.795, Acc: 30.54%\n",
            "[VGG8 - Epoch 1, Batch 200] Loss: 1.481, Acc: 37.10%\n",
            "[VGG8 - Epoch 1, Batch 300] Loss: 1.318, Acc: 41.94%\n",
            "VGG8 Epoch 1 - Train Acc: 45.00%, Test Acc: 60.42%, Time: 17.63s\n",
            "[VGG8 - Epoch 2, Batch 100] Loss: 1.143, Acc: 58.67%\n",
            "[VGG8 - Epoch 2, Batch 200] Loss: 1.092, Acc: 59.87%\n",
            "[VGG8 - Epoch 2, Batch 300] Loss: 0.998, Acc: 61.30%\n",
            "VGG8 Epoch 2 - Train Acc: 62.16%, Test Acc: 67.34%, Time: 17.29s\n",
            "[VGG8 - Epoch 3, Batch 100] Loss: 0.952, Acc: 66.48%\n",
            "[VGG8 - Epoch 3, Batch 200] Loss: 0.909, Acc: 67.11%\n",
            "[VGG8 - Epoch 3, Batch 300] Loss: 0.872, Acc: 67.84%\n",
            "VGG8 Epoch 3 - Train Acc: 68.27%, Test Acc: 70.29%, Time: 18.12s\n",
            "[VGG8 - Epoch 4, Batch 100] Loss: 0.819, Acc: 71.40%\n",
            "[VGG8 - Epoch 4, Batch 200] Loss: 0.788, Acc: 71.96%\n",
            "[VGG8 - Epoch 4, Batch 300] Loss: 0.800, Acc: 72.22%\n",
            "VGG8 Epoch 4 - Train Acc: 72.53%, Test Acc: 74.04%, Time: 17.37s\n",
            "[VGG8 - Epoch 5, Batch 100] Loss: 0.745, Acc: 74.70%\n",
            "[VGG8 - Epoch 5, Batch 200] Loss: 0.719, Acc: 74.93%\n",
            "[VGG8 - Epoch 5, Batch 300] Loss: 0.719, Acc: 75.03%\n",
            "VGG8 Epoch 5 - Train Acc: 75.30%, Test Acc: 78.23%, Time: 18.14s\n",
            "[VGG8 - Epoch 6, Batch 100] Loss: 0.658, Acc: 77.55%\n",
            "[VGG8 - Epoch 6, Batch 200] Loss: 0.686, Acc: 76.96%\n",
            "[VGG8 - Epoch 6, Batch 300] Loss: 0.674, Acc: 76.93%\n",
            "VGG8 Epoch 6 - Train Acc: 77.21%, Test Acc: 79.96%, Time: 17.93s\n",
            "[VGG8 - Epoch 7, Batch 100] Loss: 0.617, Acc: 78.58%\n",
            "[VGG8 - Epoch 7, Batch 200] Loss: 0.620, Acc: 78.87%\n",
            "[VGG8 - Epoch 7, Batch 300] Loss: 0.605, Acc: 79.15%\n",
            "VGG8 Epoch 7 - Train Acc: 79.27%, Test Acc: 78.37%, Time: 17.40s\n",
            "[VGG8 - Epoch 8, Batch 100] Loss: 0.562, Acc: 80.91%\n",
            "[VGG8 - Epoch 8, Batch 200] Loss: 0.570, Acc: 80.86%\n",
            "[VGG8 - Epoch 8, Batch 300] Loss: 0.570, Acc: 80.85%\n",
            "VGG8 Epoch 8 - Train Acc: 80.90%, Test Acc: 80.59%, Time: 18.34s\n",
            "[VGG8 - Epoch 9, Batch 100] Loss: 0.526, Acc: 82.26%\n",
            "[VGG8 - Epoch 9, Batch 200] Loss: 0.553, Acc: 81.84%\n",
            "[VGG8 - Epoch 9, Batch 300] Loss: 0.530, Acc: 81.96%\n",
            "VGG8 Epoch 9 - Train Acc: 81.93%, Test Acc: 80.43%, Time: 17.48s\n",
            "[VGG8 - Epoch 10, Batch 100] Loss: 0.501, Acc: 83.21%\n",
            "[VGG8 - Epoch 10, Batch 200] Loss: 0.511, Acc: 83.13%\n",
            "[VGG8 - Epoch 10, Batch 300] Loss: 0.500, Acc: 83.14%\n",
            "VGG8 Epoch 10 - Train Acc: 82.90%, Test Acc: 82.41%, Time: 17.34s\n",
            "\n",
            "Model Comparison Results:\n",
            "\n",
            "+----------+-----------------------+------------------+--------------------------------+\n",
            "| Model    | Final Test Accuracy   | Avg Time/Epoch   | Overfitting (Train-Test Acc)   |\n",
            "+==========+=======================+==================+================================+\n",
            "| VGG8     | 82.41%                | 17.71s           | 0.49%                          |\n",
            "+----------+-----------------------+------------------+--------------------------------+\n",
            "| VGG16_BN | 80.38%                | 24.97s           | 4.14%                          |\n",
            "+----------+-----------------------+------------------+--------------------------------+\n",
            "| AlexNet  | 76.39%                | 19.56s           | -0.66%                         |\n",
            "+----------+-----------------------+------------------+--------------------------------+\n",
            "| VGG16    | 10.00%                | 23.10s           | -0.09%                         |\n",
            "+----------+-----------------------+------------------+--------------------------------+\n",
            "\n",
            "Experiment completed. Results saved in the 'results' directory.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tabulate import tabulate\n",
        "import os\n",
        "from collections import OrderedDict\n",
        "\n",
        "# Create directory for saving results\n",
        "os.makedirs('results', exist_ok=True)\n",
        "\n",
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Hyperparameters\n",
        "batch_size = 128\n",
        "num_epochs = 10\n",
        "learning_rate = 0.001\n",
        "\n",
        "# Data transformations\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2470, 0.2435, 0.2616))\n",
        "])\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "# Define AlexNet for CIFAR-10\n",
        "class AlexNet(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(AlexNet, self).__init__()\n",
        "        # Modified AlexNet for 32x32 input\n",
        "        self.features = nn.Sequential(\n",
        "            # Layer 1\n",
        "            nn.Conv2d(3, 64, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 16x16\n",
        "\n",
        "            # Layer 2\n",
        "            nn.Conv2d(64, 192, kernel_size=3, stride=1, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 8x8\n",
        "\n",
        "            # Layer 3\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Layer 4\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "\n",
        "            # Layer 5\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),  # Output: 4x4\n",
        "        )\n",
        "\n",
        "        # Classifier\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(256 * 4 * 4, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(4096, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(1024, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "# Define VGG model with configurable depth and batch normalization\n",
        "class VGG(nn.Module):\n",
        "    def __init__(self, cfg, batch_norm=False, num_classes=10):\n",
        "        super(VGG, self).__init__()\n",
        "        self.features = self._make_layers(cfg, batch_norm)\n",
        "\n",
        "        # Calculate final feature map size based on the number of max pooling layers\n",
        "        output_size = 32 // (2 ** len([1 for x in cfg if x == 'M']))\n",
        "\n",
        "        # Calculate the feature dimension after flattening\n",
        "        flat_features = cfg[-2] * output_size * output_size  # cfg[-2] is the last conv layer's output channels\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(flat_features, 512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(512, num_classes)\n",
        "        )\n",
        "        self._initialize_weights()\n",
        "        self.batch_norm = batch_norm\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.features(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        return x\n",
        "\n",
        "    def _make_layers(self, cfg, batch_norm=False):\n",
        "        layers = []\n",
        "        in_channels = 3\n",
        "        for v in cfg:\n",
        "            if v == 'M':\n",
        "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "            else:\n",
        "                conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "                if batch_norm:\n",
        "                    layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "                else:\n",
        "                    layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "                in_channels = v\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def _initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "                if m.bias is not None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.normal_(m.weight, 0, 0.01)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "# VGG configurations - 'M' stands for max pooling\n",
        "vgg_configs = {\n",
        "    'VGG16': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M'],\n",
        "    'VGG11': [64, 'M', 128, 'M', 256, 256, 'M', 512, 512, 'M', 512, 512, 'M'],\n",
        "    'VGG8': [64, 'M', 128, 'M', 256, 'M', 512, 'M', 512, 'M']\n",
        "}\n",
        "\n",
        "# Function to visualize filters\n",
        "def visualize_filters(model, layer_idx, title, save_path):\n",
        "    # Get the weights of the specified convolutional layer\n",
        "    layers = list(model.features.children())\n",
        "    conv_layer = None\n",
        "\n",
        "    for i, layer in enumerate(layers):\n",
        "        if isinstance(layer, nn.Conv2d):\n",
        "            if layer_idx == 0:\n",
        "                conv_layer = layer\n",
        "                break\n",
        "            layer_idx -= 1\n",
        "\n",
        "    if conv_layer is None:\n",
        "        print(\"Convolutional layer not found\")\n",
        "        return\n",
        "\n",
        "    # Get the weights\n",
        "    weights = conv_layer.weight.data.cpu().numpy()\n",
        "\n",
        "    # Normalize the weights for better visualization\n",
        "    min_val = weights.min()\n",
        "    max_val = weights.max()\n",
        "    weights = (weights - min_val) / (max_val - min_val)\n",
        "\n",
        "    # Plot the first 64 filters (or all if less than 64)\n",
        "    n_filters = min(64, weights.shape[0])\n",
        "    n_cols = 8\n",
        "    n_rows = n_filters // n_cols + (1 if n_filters % n_cols != 0 else 0)\n",
        "\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(n_filters):\n",
        "        plt.subplot(n_rows, n_cols, i+1)\n",
        "\n",
        "        # For RGB input (3 channels)\n",
        "        if weights.shape[1] == 3:\n",
        "            # Convert filter to RGB image format\n",
        "            filter_img = np.transpose(weights[i], (1, 2, 0))\n",
        "            plt.imshow(filter_img)\n",
        "        else:\n",
        "            # For single channel, just show the first input channel's filter\n",
        "            plt.imshow(weights[i, 0], cmap='viridis')\n",
        "\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f'{title} - First Layer Filters', fontsize=16)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "# Function to visualize feature maps\n",
        "def visualize_feature_maps(model, layer_idx, image, title, save_path):\n",
        "    # Create a new model that outputs the feature maps of the specified layer\n",
        "    features = []\n",
        "\n",
        "    def hook_fn(module, input, output):\n",
        "        features.append(output.detach().cpu().numpy())\n",
        "\n",
        "    # Find the specific layer\n",
        "    layer_count = 0\n",
        "    target_layer = None\n",
        "\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "            if layer_count == layer_idx:\n",
        "                target_layer = module\n",
        "                break\n",
        "            layer_count += 1\n",
        "\n",
        "    if target_layer is None:\n",
        "        print(f\"Could not find convolutional layer at index {layer_idx}\")\n",
        "        return\n",
        "\n",
        "    # Register hook\n",
        "    hook = target_layer.register_forward_hook(hook_fn)\n",
        "\n",
        "    # Forward pass with our image\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        model(image.unsqueeze(0).to(device))\n",
        "\n",
        "    # Remove the hook\n",
        "    hook.remove()\n",
        "\n",
        "    # Get the feature maps\n",
        "    feature_maps = features[0][0]\n",
        "\n",
        "    # Plot the feature maps\n",
        "    n_features = min(64, feature_maps.shape[0])\n",
        "    n_cols = 8\n",
        "    n_rows = n_features // n_cols + (1 if n_features % n_cols != 0 else 0)\n",
        "\n",
        "    plt.figure(figsize=(15, 15))\n",
        "    for i in range(n_features):\n",
        "        plt.subplot(n_rows, n_cols, i+1)\n",
        "        plt.imshow(feature_maps[i], cmap='viridis')\n",
        "        plt.axis('off')\n",
        "\n",
        "    plt.suptitle(f'{title} - Feature Maps of Layer {layer_idx+1}', fontsize=16)\n",
        "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
        "    plt.savefig(save_path)\n",
        "    plt.close()\n",
        "\n",
        "# Function to train models\n",
        "def train_and_evaluate(model, model_name, optimizer, criterion, epochs):\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    test_losses = []\n",
        "    test_accuracies = []\n",
        "    times_per_epoch = []\n",
        "\n",
        "    best_accuracy = 0.0\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        start_time = time.time()\n",
        "\n",
        "        for i, data in enumerate(trainloader, 0):\n",
        "            inputs, labels = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "            if i % 100 == 99:\n",
        "                print(f'[{model_name} - Epoch {epoch+1}, Batch {i+1}] Loss: {running_loss/100:.3f}, Acc: {100*correct/total:.2f}%')\n",
        "                running_loss = 0.0\n",
        "\n",
        "        epoch_time = time.time() - start_time\n",
        "        times_per_epoch.append(epoch_time)\n",
        "\n",
        "        # Calculate train accuracy\n",
        "        train_accuracy = 100 * correct / total\n",
        "        train_accuracies.append(train_accuracy)\n",
        "\n",
        "        # Calculate test accuracy\n",
        "        model.eval()\n",
        "        test_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for data in testloader:\n",
        "                images, labels = data[0].to(device), data[1].to(device)\n",
        "                outputs = model(images)\n",
        "                loss = criterion(outputs, labels)\n",
        "                test_loss += loss.item()\n",
        "                _, predicted = torch.max(outputs.data, 1)\n",
        "                total += labels.size(0)\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        test_accuracy = 100 * correct / total\n",
        "        test_accuracies.append(test_accuracy)\n",
        "        test_losses.append(test_loss / len(testloader))\n",
        "\n",
        "        print(f'{model_name} Epoch {epoch+1} - '\n",
        "              f'Train Acc: {train_accuracy:.2f}%, Test Acc: {test_accuracy:.2f}%, '\n",
        "              f'Time: {epoch_time:.2f}s')\n",
        "\n",
        "        # Save the best model\n",
        "        if test_accuracy > best_accuracy:\n",
        "            best_accuracy = test_accuracy\n",
        "            torch.save(model.state_dict(), f'results/{model_name}_best.pth')\n",
        "\n",
        "        # Visualize feature maps after half training and at the end\n",
        "        if epoch == epochs // 2 - 1 or epoch == epochs - 1:\n",
        "            # Get a sample image from the test set\n",
        "            sample_data = next(iter(testloader))\n",
        "            sample_image = sample_data[0][0].to(device)\n",
        "\n",
        "            visualize_feature_maps(\n",
        "                model, 0, sample_image,\n",
        "                f'{model_name} - Epoch {epoch+1}',\n",
        "                f'results/{model_name}_feature_maps_epoch{epoch+1}.png'\n",
        "            )\n",
        "\n",
        "    # Calculate average time per epoch\n",
        "    avg_time_per_epoch = sum(times_per_epoch) / len(times_per_epoch)\n",
        "\n",
        "    # Save the final model\n",
        "    torch.save(model.state_dict(), f'results/{model_name}_final.pth')\n",
        "\n",
        "    # Visualize filters of the first layer\n",
        "    visualize_filters(model, 0, model_name, f'results/{model_name}_filters.png')\n",
        "\n",
        "    return {\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'test_accuracies': test_accuracies,\n",
        "        'test_losses': test_losses,\n",
        "        'avg_time_per_epoch': avg_time_per_epoch,\n",
        "        'final_test_accuracy': test_accuracies[-1]\n",
        "    }\n",
        "\n",
        "# Plot training curves\n",
        "def plot_training_curves(results_dict):\n",
        "    plt.figure(figsize=(20, 10))\n",
        "\n",
        "    # Plot training accuracy\n",
        "    plt.subplot(2, 2, 1)\n",
        "    for model_name, results in results_dict.items():\n",
        "        plt.plot(range(1, len(results['train_accuracies'])+1), results['train_accuracies'], marker='o', label=model_name)\n",
        "    plt.title('Training Accuracy', fontsize=16)\n",
        "    plt.xlabel('Epochs', fontsize=14)\n",
        "    plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot test accuracy\n",
        "    plt.subplot(2, 2, 2)\n",
        "    for model_name, results in results_dict.items():\n",
        "        plt.plot(range(1, len(results['test_accuracies'])+1), results['test_accuracies'], marker='o', label=model_name)\n",
        "    plt.title('Test Accuracy', fontsize=16)\n",
        "    plt.xlabel('Epochs', fontsize=14)\n",
        "    plt.ylabel('Accuracy (%)', fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot test loss\n",
        "    plt.subplot(2, 2, 3)\n",
        "    for model_name, results in results_dict.items():\n",
        "        plt.plot(range(1, len(results['test_losses'])+1), results['test_losses'], marker='o', label=model_name)\n",
        "    plt.title('Test Loss', fontsize=16)\n",
        "    plt.xlabel('Epochs', fontsize=14)\n",
        "    plt.ylabel('Loss', fontsize=14)\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot average time per epoch\n",
        "    plt.subplot(2, 2, 4)\n",
        "    model_names = list(results_dict.keys())\n",
        "    avg_times = [results_dict[name]['avg_time_per_epoch'] for name in model_names]\n",
        "    plt.bar(model_names, avg_times)\n",
        "    plt.title('Average Time per Epoch', fontsize=16)\n",
        "    plt.xlabel('Model', fontsize=14)\n",
        "    plt.ylabel('Time (seconds)', fontsize=14)\n",
        "    for i, time_val in enumerate(avg_times):\n",
        "        plt.text(i, time_val + 0.05, f'{time_val:.2f}s', ha='center')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('results/training_curves_comparison.png')\n",
        "    plt.close()\n",
        "\n",
        "# Compare final results in a table\n",
        "def compare_final_results(results_dict):\n",
        "    # Prepare data for tabulation\n",
        "    data = []\n",
        "    headers = ['Model', 'Final Test Accuracy', 'Avg Time/Epoch', 'Overfitting (Train-Test Acc)']\n",
        "\n",
        "    for model_name, results in results_dict.items():\n",
        "        final_train_acc = results['train_accuracies'][-1]\n",
        "        final_test_acc = results['test_accuracies'][-1]\n",
        "        avg_time = results['avg_time_per_epoch']\n",
        "        overfitting_measure = final_train_acc - final_test_acc\n",
        "\n",
        "        data.append([\n",
        "            model_name,\n",
        "            f\"{final_test_acc:.2f}%\",\n",
        "            f\"{avg_time:.2f}s\",\n",
        "            f\"{overfitting_measure:.2f}%\"\n",
        "        ])\n",
        "\n",
        "    # Sort by test accuracy (descending)\n",
        "    data.sort(key=lambda x: float(x[1][:-1]), reverse=True)\n",
        "\n",
        "    # Print table\n",
        "    print(\"\\nModel Comparison Results:\\n\")\n",
        "    print(tabulate(data, headers, tablefmt=\"grid\"))\n",
        "\n",
        "    # Save to file\n",
        "    with open('results/model_comparison_results.txt', 'w') as f:\n",
        "        f.write(\"Model Comparison Results:\\n\\n\")\n",
        "        f.write(tabulate(data, headers, tablefmt=\"grid\"))\n",
        "        f.write(\"\\n\\nAnalysis:\\n\")\n",
        "\n",
        "        # Add analysis of the best model\n",
        "        best_model = data[0][0]\n",
        "        f.write(f\"\\n1. {best_model} achieved the best performance with {data[0][1]} test accuracy.\")\n",
        "\n",
        "        # Analyze overfitting\n",
        "        min_overfitting_idx = min(range(len(data)), key=lambda i: float(data[i][3][:-1]))\n",
        "        f.write(f\"\\n2. {data[min_overfitting_idx][0]} showed the least overfitting ({data[min_overfitting_idx][3]}).\")\n",
        "\n",
        "        # Analyze efficiency\n",
        "        min_time_idx = min(range(len(data)), key=lambda i: float(data[i][2][:-1]))\n",
        "        f.write(f\"\\n3. {data[min_time_idx][0]} was the most efficient, taking only {data[min_time_idx][2]} per epoch.\")\n",
        "\n",
        "        # Concluding remark\n",
        "        f.write(\"\\n\\nConclusion: \")\n",
        "        if best_model == data[min_overfitting_idx][0] and best_model == data[min_time_idx][0]:\n",
        "            f.write(f\"{best_model} offers the best balance of accuracy, generalization, and efficiency.\")\n",
        "        else:\n",
        "            f.write(f\"Different models excel in different aspects. Consider the trade-offs between accuracy ({data[0][0]}), \"\n",
        "                   f\"generalization ({data[min_overfitting_idx][0]}), and efficiency ({data[min_time_idx][0]}).\")\n",
        "\n",
        "# Main execution\n",
        "def main():\n",
        "    print(f\"CIFAR-10 CNN Architecture Experiment\")\n",
        "    print(f\"===================================\")\n",
        "    print(f\"Training on device: {device}\")\n",
        "\n",
        "    # Initialize results dictionary\n",
        "    all_results = {}\n",
        "\n",
        "    # Define and train AlexNet\n",
        "    print(\"\\n[AlexNet Training]\")\n",
        "    alexnet_model = AlexNet().to(device)\n",
        "    alexnet_optimizer = optim.Adam(alexnet_model.parameters(), lr=learning_rate)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    alexnet_results = train_and_evaluate(alexnet_model, \"AlexNet\", alexnet_optimizer, criterion, num_epochs)\n",
        "    all_results[\"AlexNet\"] = alexnet_results\n",
        "\n",
        "    # Define and train VGG16 (without batch norm)\n",
        "    print(\"\\n[VGG16 Training]\")\n",
        "    vgg16_model = VGG(vgg_configs['VGG16'], batch_norm=False).to(device)\n",
        "    vgg16_optimizer = optim.Adam(vgg16_model.parameters(), lr=learning_rate)\n",
        "    vgg16_results = train_and_evaluate(vgg16_model, \"VGG16\", vgg16_optimizer, criterion, num_epochs)\n",
        "    all_results[\"VGG16\"] = vgg16_results\n",
        "\n",
        "    # Define and train VGG16 with batch normalization\n",
        "    print(\"\\n[VGG16 with BatchNorm Training]\")\n",
        "    vgg16bn_model = VGG(vgg_configs['VGG16'], batch_norm=True).to(device)\n",
        "    vgg16bn_optimizer = optim.Adam(vgg16bn_model.parameters(), lr=learning_rate)\n",
        "    vgg16bn_results = train_and_evaluate(vgg16bn_model, \"VGG16_BN\", vgg16bn_optimizer, criterion, num_epochs)\n",
        "    all_results[\"VGG16_BN\"] = vgg16bn_results\n",
        "\n",
        "    # Define and train VGG8 (reduced depth)\n",
        "    print(\"\\n[VGG8 Training]\")\n",
        "    vgg8_model = VGG(vgg_configs['VGG8'], batch_norm=True).to(device)\n",
        "    vgg8_optimizer = optim.Adam(vgg8_model.parameters(), lr=learning_rate)\n",
        "    vgg8_results = train_and_evaluate(vgg8_model, \"VGG8\", vgg8_optimizer, criterion, num_epochs)\n",
        "    all_results[\"VGG8\"] = vgg8_results\n",
        "\n",
        "    # Plot all training curves\n",
        "    plot_training_curves(all_results)\n",
        "\n",
        "    # Compare final results\n",
        "    compare_final_results(all_results)\n",
        "\n",
        "    print(\"\\nExperiment completed. Results saved in the 'results' directory.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    }
  ]
}